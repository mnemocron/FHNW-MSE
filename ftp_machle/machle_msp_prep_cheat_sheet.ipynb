{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb89e69d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left\"> <b> Machine Learning </b> <br> MSE FTP MachLe <br> \n",
    "<a href=\"mailto:simon.burkhardt@fhnw.ch\"> Simon Burkhardt </a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efae1e",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "FS2021 - Examp Preparaion Notes / Cheat Sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99416685",
   "metadata": {},
   "source": [
    "#### How to use this sheet?\n",
    "\n",
    "> This is a collection of the most important Machine Learning facts gathered in a form to quickly find information during an exam.\n",
    "> Use `CTRL+F` during the exam to search for the topic that you are working on or to answer an question.\n",
    "\n",
    "> for general questions answer with:\n",
    ">- \"It depends ... \"\n",
    ">- \"In the case of ... I would do ...\"\n",
    "\n",
    "\n",
    "---\n",
    "this sheet is WIP\n",
    "\n",
    "**Todo**\n",
    "\n",
    "- MAP (max a posteriori)\n",
    "- max likelihood\n",
    "- Bayesian Mathematics\n",
    "- Regularization for Regression & regularization parameter λ\n",
    "- Bayesian Belief Networks\n",
    "\n",
    "#### Exam Prompts\n",
    "\n",
    "How can this learner be improved?\n",
    "\n",
    "Would {...} help to improve this scenario?\n",
    "\n",
    "- dimmensionality reduction\n",
    "- feature transformation\n",
    "- etc...\n",
    "\n",
    "\n",
    "- Which model is more sensitive to outliers?\n",
    "- Which models can generate data from learned data?\n",
    "- Which models can complete missing values in a dataset?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe6f3d",
   "metadata": {},
   "source": [
    "### What Problems are solved by it\n",
    "\n",
    "- **Predictive Modelling** to estimate a new observation --> **regression**\n",
    "- **Explanatory Modelling** to describe the outcome when an input changes --> **classifiers**\n",
    "- **Optimizaion** to find the most relevant inputs for an optimal performance --> **dimmenstionality reduction**\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- **Supervised** Learning if you have labeled data available\n",
    "- **Unsupervised** Learning if no labels are available but you want to find patterns / clusters / structure\n",
    "- **Reinforcement** Learning to learn policies\n",
    "\n",
    "\n",
    "<img src=\"mindmaps/machine_learning_mind_map_6.png\" width=\"100%\"/>\n",
    "\n",
    "- note that **decision tree** and **random forrest** classifiers belong to the **ensemble methods**\n",
    "- note that **SVC** can also be used in **regression**\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Measurement Techniques\n",
    "\n",
    "What should be optimized?\n",
    "--> generally speaking: some score on the test set (not the training set)\n",
    "\n",
    "| name | calc |\n",
    "|:-----|:-----|\n",
    "| Accuracy | $$\\frac{correct}{all}=(1-error)$$ |\n",
    "| Error | $$\\frac{wrong}{all}=(1-accuracy)$$ |\n",
    "| Precision | $$\\frac{TP}{TP+FP}$$ |\n",
    "| Recall / Sensitivity | $$\\frac{TP}{TP+FN}$$ |\n",
    "| Specifity | $$\\frac{TN}{TN+FP}$$ |\n",
    "| F1 Score | $$2\\frac{Precision \\cdot Recall}{Precision + Recall}$$ |\n",
    "\n",
    "\n",
    "<img src=\"images/error_curve.png\" width=\"50%\"/>\n",
    "\n",
    "#### Recall Precision Curve (RPC) and Recall Operator Curve (ROC)\n",
    "\n",
    "AUC = Area Under Curve\n",
    "\n",
    "<img src=\"images/rpc_roc.png\" width=\"90%\"/>\n",
    "\n",
    "\n",
    "#### Confusion Matrix\n",
    "\n",
    "<img src=\"images/confusion_matrix.png\" width=\"30%\"/>\n",
    "\n",
    "### Comparison\n",
    "\n",
    "<img src=\"images/5-Table1-1.png\" width=\"100%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aecee25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Basics\n",
    "\n",
    "### Explain in your own words what _overfitting_ and _underfitting_ is\n",
    "\n",
    "(guaranteed exam question)\n",
    "\n",
    "**Overfitting** is when the model is too detailed and only learns the data by heart instead of generalizing and simplifying the data into a usable model.\n",
    "\n",
    "**Underfitting** is when the model is too simple and not able to fit important variations in the data.\n",
    "\n",
    "### Explain \"_the curse of dimensionality_\" (with an example)\n",
    "\n",
    "One of the characteristics of high-dimensional data is that the number of dimensions is \n",
    "comparable or larger than the number of samples.\n",
    "\n",
    "The more dimmenstions a dataset has, the more data is required to draw relevant conclusions from this dataset. \n",
    "The amount of data needed to support the result often grows exponentially with the dimensionality.\n",
    "\n",
    "**Example**: Say, you dropped a coin on a 100-meter line. How do you find it? Simple, just walk on the line and search. But what if it’s 100 x 100 sq. m. field? It’s already getting tough, trying to search a (roughly) football ground for a single coin. But what if it’s 100 x 100 x 100 cu.m space?! \n",
    "\n",
    "Curse of dimensionality experiment using **Norm**. \n",
    "Calculate the distance between two random points in a n-dimensional space.\n",
    "With low dimensions, the variance is high. With high dimensions the variance in the distance is low --> all arbitrary points are on average equally spaced.\n",
    "\n",
    "\n",
    "### What is the \"_no free lunch theorem_\"?\n",
    "\n",
    "For good generalization performance, there is no context-independent or usage-independent reason to favor one learning method over another.\n",
    "\n",
    "The theorem states that all optimization algorithms perform equally well when their performance is averaged across all possible problems.\n",
    "\n",
    "e.g. You cannot say things like _\"You must use KNN for your task because it performed best on my previous project\"_\n",
    "\n",
    "### What is \"_Occam's Razor_\"?\n",
    "\n",
    "When presented with competing hypotheses that make the same predictions, one should select the solution with the fewest assumptions.\n",
    "\n",
    "\n",
    "### Explain the \"_Bias Variance Dilemma_\"\n",
    "\n",
    "- **Bias** is an error caused by false assumptions and causes the algorithm to miss important features --> leads to **underfitting**\n",
    "- **Variance** is an error from sensitivity to fluctuations in the training data --> high variance leads to learning the noise and therefore **overfitting**\n",
    "\n",
    "Adding more basis functions in a linear model . . .\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| . . . decreases model bias. | ✅ |  |\n",
    "| . . . decreases estimation bias.  |  | ❌ |\n",
    "| . . . decreases variance.  |  | ❌ |\n",
    "| . . . doesn’t aﬀect bias and variance.  |  | ❌ |\n",
    "\n",
    "\n",
    "### Can a training Error = 0 always be achieved?\n",
    "\n",
    "(general question)\n",
    "\n",
    "(**for which algorithm is this true?**) **No**. The model is learning a function (every input maps to a unique output). \n",
    "So, two different outputs for the very same feature value is not possible!\n",
    "\n",
    "In other words, it depends on the model. If the model is too simple there will be underfitting with a lot of error.\n",
    "\n",
    "### Given m i.i.d. data points, the training error converges to the true error as m → ∞.\n",
    "\n",
    "This is true, if we assume that the data points are i.i.d. (independent and identically distributed).\n",
    "A few students pointed out that this might not be the case.\n",
    "\n",
    "### Thinking about unsupervised learning, which ones of the following statements are true (multiple choice) ?\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| Diﬀerently from partitional graph based algorithms and density estimation algorithms the K-means and the EM algorithm need the number of clusters as an input parameter. | ✅ |  |\n",
    "| With hierarchical clustering algorithms based on graph theory we obtain a partition of a dataset in K diﬀerent classes. (minimal spanning tree) | ✅ |  |\n",
    "| The K-Means algorithm obtains a global optimal solution for the partition of a dataset by minimizing the square distance between examples and their nearest centroid. |  | ❌ |\n",
    "| The EM algorithm assumes that the model of the data comes from a mixture of K n-dimensional probability distributions. |  | ❌ |\n",
    "\n",
    "K-means is sensitive to the seed centroids --> not the optimal solution\n",
    "\n",
    "### How do you ensure you’re not overﬁtting with a model ?\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| Keep the model simpler: reduce variance by taking into account fewer variables and parameters, thereby removing some of the noise in the training data. | ✅ |  |\n",
    "| Use cross-validation techniques such as k-fold cross-validation. |  | ❌ |\n",
    "| Use regularization techniques such as LASSO that penalize certain model parameters if they’re likely to cause overﬁtting. | ✅ |  |\n",
    "| Generating an ensemble of learners and using a softmax or voting output. | ✅ |  |\n",
    "\n",
    "Cross-Validation does not change the learner (!)\n",
    "\n",
    "### What causes Bias?\n",
    "\n",
    "- too simple assumptions / underfitting\n",
    "\n",
    "\n",
    "### What are the different subsets of the available data splits used for?\n",
    "\n",
    "- **Training Set** to train the parameters of the **model** itself\n",
    "- **Validation Set** used to **tune the hyperparameters** of the model\n",
    "- **Test Set** to estimate the true error\n",
    "\n",
    "\n",
    "### Regularization\n",
    "\n",
    "Parametrically controlling model complexity by introducing a penalty. Penalty is weighted with the regularization parameter $\\lambda$\n",
    "\n",
    "To avoid overfitting.\n",
    "\n",
    "Linear Models -- usually implemented in forms of constraints on the weights\n",
    "- Ridge regression (L2 regularization)\n",
    "- LASSO regression (L1 regularization) \n",
    "\n",
    "Support Vector Machines (SVM)\n",
    "- Parameter “C” controls the margin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8bc4e4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data Management\n",
    "\n",
    "Business Understanding -- Question/ Problem Formulation\n",
    "- What problems are we trying to solve?\n",
    "- What is our hypothesis (prior knowledge)?\n",
    "- What is our metric of success?\n",
    "\n",
    "Data Understanding\n",
    "- Do we already have relevant data?\n",
    "- Where are the biases, anomalies or other issues with the data?\n",
    "- How to transform the data to enable effective analysis?\n",
    "\n",
    "Data Preparation\n",
    "- What data do we have and what data do we need?\n",
    "- How will we collect more data?\n",
    "- How will we organize the data?\n",
    "\n",
    "Modeling and Evaluation\n",
    "- What does the data say about the world?\n",
    "- Does it actually answer the question we are looking for?\n",
    "- How robust are the conclusions?\n",
    "\n",
    "> \"Good data preparation includes **cleaning**, **transforming** and **aggregating** model \n",
    "inputs as well as the identification and treatment of **outliers**.\"\n",
    "\n",
    "Data Cleaning\n",
    "- Fix input errors, typos, remove duplicates, etc.\n",
    "\n",
    "Imputation\n",
    "- Fix missing values\n",
    "\n",
    "Transformations\n",
    "- Binarization, One-hot-encoding\n",
    "- Binning -- discretize numeric values\n",
    "- BoxCox/ Power Transformation\n",
    "\n",
    "Scaling and Normalization\n",
    "- whiting, c.f. PCA, gradient descent methods\n",
    "\n",
    "\n",
    "### Why do you need to encode your data?\n",
    "\n",
    "**One hot encoding** is necessary to make features independent\n",
    "- e.g. the name of a town\n",
    "- the algotithm shall not find a generalization that correlates with the length of the town name. or the value of the zip code\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Feature Design\n",
    "- statistical values of “raw data”, e.g. mean, median, var, etc.\n",
    "- Domain knowledge/ invariances!\n",
    "- Simplification, reduce redundancies\n",
    "\n",
    "Feature Combination\n",
    "- e.g., 3D motion vector from x,y,z gyroscope\n",
    "\n",
    "Feature expansion\n",
    "- c.f. SVM (kernel trick) \n",
    "\n",
    "Feature Selection\n",
    "- \"What are relevant features for predicting the task at hand?\"\n",
    "- Reducing the number of Features in order to\n",
    "    + reduce overfitting and hence improve generalization -- **decrease dimensions**;\n",
    "    + to gain a better understanding of relevant features and their influence on the output -- **explainability & interpretability**\n",
    "\n",
    "Univariate Feature Selection\n",
    "- correlation between a feature and the target variable\n",
    "\n",
    "Regularization\n",
    "- e.g., linear model + Lasso, Ridgid \n",
    "\n",
    "Subset Selection\n",
    "- Feed forward Feature Selection\n",
    "- Backwards Feature Selection (Recursive Feature Elimination)\n",
    "- combinations\n",
    "\n",
    "Model based Feature Ranking\n",
    "• e.g., random forests (cf. last lecture)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc86d7a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Classifiers\n",
    "\n",
    "### A classiﬁer trained on less training data is less likely to overﬁt?\n",
    "\n",
    "This is false. A speciﬁc classiﬁer (with some ﬁxed model complexity) will be more likely\n",
    "to overﬁt to noise in the training data when there is less training data, and is therefore\n",
    "more likely to overﬁt.\n",
    "\n",
    "### What is the difference between a classifier and an estimator?\n",
    "\n",
    "**estimator**: This isn't a word with a rigorous definition but it usually associated with finding a current value in data. it is most frequently used in conjunction with **parameter estimation** or **density estimation**.\n",
    "The estimator then would be the method of generating estimations, for example the method of **maximum likelihood**.\n",
    "\n",
    "**classifier**: This specifically refers to a type of function where the response is **discrete**. Compared to this a regressor will have a continuous response. \n",
    "\n",
    "### What is the difference between a generative model and a discriminative model?\n",
    "\n",
    "- A **Generative** Model explicitly models the actual distribution of each class.\n",
    "- A **Discriminative** model models the decision boundary between the classes. \n",
    "\n",
    "**Generative classifiers**\n",
    "\n",
    "- Naïve Bayes\n",
    "- Bayesian networks\n",
    "- Markov random fields\n",
    "- Hidden Markov Models (HMM)\n",
    "\n",
    "**Discriminative Classifiers**\n",
    "\n",
    "- Logistic regression\n",
    "- Suport Vector Machine (SVM)\n",
    "- Traditional neural networks\n",
    "- k-Nearest neighbour (KNN)\n",
    "- Conditional Random Fields (CRF)\n",
    "\n",
    "What happens when training data is biased over one class in Generative Model?\n",
    "What happens when training data is biased over one class in Discriminative Models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bde6d3",
   "metadata": {},
   "source": [
    "## KNN - k-nearest Neighbour\n",
    "\n",
    "> KNN is good for low dimmensions\n",
    "> - for many features (e.g. pixles) the data must be broken down\n",
    "\n",
    "kNN cannot extrapolate outside of the min/max of the dataset --> **limited regression**\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| The classiﬁcation accuracy is better with larger values of k. |  | ❌ | \n",
    "| The decision boundary is smoother with smaller values of k.  |  | ❌ |\n",
    "| The decision boundary is linear. |  | ❌ |\n",
    "| k-NN does not require an explicit training step. | ✅ |  |\n",
    "\n",
    "### How can you prevent K-means algorithm from getting stuck in bad local optima ?\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| Set the same seed value for each run. |  | ❌ |\n",
    "| Use multiple random initializations.  | ✅ |  |\n",
    "| Taking bootstrap samples of the data and run it several times. | ✅ |  |\n",
    "| Using K-means++ | ✅ |  |\n",
    "\n",
    "\n",
    "### Given a k-NN classiﬁer which ones of the following statements are true (multiple choice) \n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| The more examples are used for classifying an example, the higher is the accuracy we obtain. (no help if overlap in data) |  | ❌ |\n",
    "| The more attributes we use to describe the examples the more diﬀcult it is to obtain high accuracy. | ✅ |  |\n",
    "| The most costly part of this method is to learn the model. |  | ❌ |\n",
    "| We can use k-NN for classiﬁcation and regression. | ✅ |  |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9a0e7",
   "metadata": {},
   "source": [
    "## SVM/SVC - Support Vector Machine\n",
    "\n",
    "- SVC = only a classifier\n",
    "- SVM = classifier with built in Kernel Trick\n",
    "\n",
    "**Classifier** and **Regression**\n",
    "\n",
    "SVM family of classifiers\n",
    "\n",
    "1. (Maximal margin) hyperplane classifier (for linearly separable data)\n",
    "2. Support Vector **Classifier** SVC (for almost linearly separable soft margins, slack variable)\n",
    "3. Support Vector **Machine** SVM (for non linearly separable data, **Kernel Classifiers**)\n",
    "\n",
    "- SVMs do not directly provide **probability estimates**, these are calculated using an expensive five-fold cross-validation\n",
    "\n",
    "Advantages\n",
    "- SVMs are effective in high dimensional spaces\n",
    "- _\"SVM are still eﬀective in cases where number of dimensions d is greater than the number of samples N\"_\n",
    "- insensitive to distant points\n",
    "- only the closest points (support vectors) are required to describe the model (memory efficient)\n",
    "\n",
    "Disadvantages\n",
    "- sensitive to noise\n",
    "- not scale invariant, so it is highly recommended to scale your data\n",
    "- not suitable for large data sets\n",
    "- not suited for \n",
    "- the SVC does not output a probability of a classification\n",
    "\n",
    "### Explain the workings of the $C$ and $\\gamma$ parameters\n",
    "\n",
    "Parameters $C$ and $\\gamma$ (with Gaussian kernel) allow to adjust the flexibility of SVM (bias variance \n",
    "trade off) \n",
    "\n",
    "The parameter $C$ controlls the **Soft Margins** version of the SVC where the data is not linearly separable but **misclassification is penalized** with the weight $C$.\n",
    "\n",
    "- If you have a lot of noisy observations you should decrease $C$\n",
    "- **decreasing $C$** corresponds to **more regularization**, **larger margin**, **higher tolerance** for misclassification, **less confidence** in the dataset (more noise)\n",
    "\n",
    "**RBF Kernel** has the parameter $\\gamma$\n",
    "\n",
    "$$\n",
    "K(x_i,x_j)=exp( -\\gamma ||x_i - x_j||^2 )\n",
    "$$\n",
    "\n",
    "> Intuitively, the **gamma** parameter defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.\n",
    "\n",
    "> The behavior of the model is very sensitive to the gamma parameter. If gamma is too large, the radius of the area of influence of the support vectors only includes the support vector itself and no amount of regularization with C will be able to prevent overfitting.\n",
    "\n",
    "> When gamma is very small, the model is too constrained and cannot capture the complexity or “shape” of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes.\n",
    "\n",
    "### What do you do when the data is not linearly sepparable?\n",
    "\n",
    "Increase the dimensionality by transforming the data into a higher dimensional feature space\n",
    "\n",
    "### Write down and explain the primal loss function of a SVC for a binary classification problem\n",
    "\n",
    "When the data is linearly separable by a hyperplane, many hyperplanes will fit in between them.\n",
    "The question is, which plane separates the data the best?\n",
    "There needs to be a loss function to maximize the distance to each supporting point.\n",
    "Normalization is also needed in the form of the **geometric margin**.\n",
    "\n",
    "minimax Problem: find the minimal distance, and then maximize this minimal distance.\n",
    "\n",
    "### Explain the Representer Theorem \n",
    "\n",
    "The Representer Theorem states that the solution 𝑤∗ of the optimization problem can always \n",
    "be written as a linear combination of the training data:\n",
    "\n",
    "### Why is it important to scale the inputs when using SVM?\n",
    "\n",
    "> SVMs try to ﬁt the largest possible «street» between the classes (see the ﬁrst answer), so if the training set is not scaled, the SVM will tend to neglect small features.\n",
    "\n",
    "### What is the fundamental idea behind SVMs?\n",
    "\n",
    "> The fundamental idea behind Support Vector Machines is to ﬁt the widest possible «street»between the classes. In other words, the goal is to have the largest possible margin between the decision boundary that separates the two classes and the training instances.\n",
    "When performing soft margin classiﬁcation, the SVM searches for a compromise between perfectly separating the two classes and having the widest possible street (i.e., a few in-stances may end up on the street). Another key idea is to use kernels when training on nonlinear datasets.\n",
    "\n",
    "### What is a support vector?\n",
    "\n",
    "> After training an SVM, a support vector is **any instance located on the «street», including its border**. The decision boundary is entirely determined by the support vectors. Any instance that is not a support vector (i.e., oﬀ the street) has no inﬂuence whatsoever; you could remove them, add more instances, or move them around, and as long as they stay oﬀ the street they won’t aﬀect the decision boundary. Computing the predictions only involves the support vectors, not the whole training set.\n",
    "\n",
    "### Can an SVM output a conﬁdence score when it classiﬁes an instance? What about a probability?\n",
    "\n",
    "cnofidence: **YES** / probability: **NO**\n",
    "\n",
    "> An SVM classiﬁer can output the distance between the test instance and the decision boundary, and you can use this as a conﬁdence score. However, this score cannot be directly converted into an estimation of the class probability. If you set probability=True when creating an SVM in Scikit-Learn, then after training it will calibrate the probabilities using Logistic Regression on the SVM’s scores (trained by an additional ﬁve-fold cross-validation on the training data). This will add the `predict_proba()` and `predict_log_proba()` methods to the SVM.\n",
    "\n",
    "### Should you use the primal or the dual form of the SVM problem to train a  model on a training set with millions of instances and hundreds of features?\n",
    "\n",
    "> This question applies only to linear SVMs since kernelized can only use the dual form. The computational complexity of the primal form of the SVM problem is proportional to the number of training instances N, while the computational complexity of the dual form is proportional to a number between N2 and N3. So if the3re are millions of instances, you should deﬁnitely use the primal form, because the dual form will be much too slow.\n",
    "\n",
    "### Say you trained an SVM classiﬁer with an RBF kernel. It seems to underﬁt  the training set: should you increase or decrease γ? What about C?\n",
    "\n",
    "> If an SVM classiﬁer trained with an RBF kernel underﬁts the training set, there might be too much regularization. To decrease it, you need to increase $\\gamma$ or $C$ (or both).\n",
    "\n",
    "### What are Lagrange-Multipliers and why are they used in SVM?\n",
    "\n",
    "(Quadratic Optimization)\n",
    "\n",
    "To get rid of the linear inequality constraints, one usually applies Lagrange multipliers\n",
    "\n",
    "### What is a dual form of an optimizaiton problem?\n",
    "\n",
    "> At first sight the dual form appears to have the disadvantage of a K-NN classifier — it requires \n",
    "the training data points $x_i$. However, many of the $a_i$'s are zero. The ones that are non-zero \n",
    "define the support vectors $x_i$.\n",
    "\n",
    "> Solving the primal problem, we obtain the optimal $w$, but **know nothing about the $a_i$**. In order to classify a query point $x$ we need to explicitly compute the scalar product $w^Tx$, which **may be expensive if $d$ is large**.\n",
    "Solving the dual problem, we obtain the $a_i$\n",
    "(where $a_i=0$ for all but a few points - the support vectors). In order to classify a query point $x$, we calculate\n",
    ">$$\n",
    "w^Tx+w_0= \\left( \\sum_{i=1}^{n} a_i y_i x_i \\right)^T x+w_0= \\sum_{i=1}^{n} a_i y_i ⟨xi,x⟩+w_0\n",
    "$$\n",
    ">This term is **very efficiently** calculated if there are only few support vectors. Further, since we now have a scalar product only involving data vectors, we may apply the **kernel trick**.\n",
    "\n",
    "### What does the geometric margin say?\n",
    "\n",
    "The geometric margin is a way to measure the distance betwenn the separating hyperplane and the data points.\n",
    "\n",
    "> The geometric margin is invariant to rescaling of the parameters; i.e., if we replace 𝒘 with \n",
    "𝟐𝒘 and 𝒃 with 𝟐𝒃, then the geometric margin does not change.\n",
    "\n",
    "### How do you distinguish \"linearly non-separable classes\"?\n",
    "\n",
    "1. if the classes only slightly overlap: use **Soft Margin SVC** with the correct regularization $C$\n",
    "2. if the classes overlap more: transform to higher dimensional space using the **Kernel Trick** in a **SVM**\n",
    "\n",
    "### What is the Kernel Trick and how is it useful?\n",
    "\n",
    "> The Kernel trick involves kernel functions that can enable **in higher-dimension spaces**\n",
    "**without** explicitly **calculating the coordinates of points** within that dimension: instead,\n",
    "kernel functions compute the inner products between the images of all pairs of data in a\n",
    "feature space. This allows them the very useful attribute of calculating the coordinates\n",
    "of higher dimensions while being **computationally cheaper** than the explicit calculation\n",
    "of said coordinates. Many algorithms can be expressed in terms of inner products. Using\n",
    "the kernel trick enables us eﬀectively run algorithms in a high-dimensional space with\n",
    "lower-dimensional data.\n",
    "\n",
    "### What is the complexity of the kernel trick?\n",
    "\n",
    "> The Complexity of learning depends on $N$, typically it is $O(N^3)$ , not on $D$\n",
    "\n",
    "- N dimensional vector\n",
    "- D dimensional space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6f863",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "> However, although naive Bayes is known as a decent classiﬁer,\n",
    "it is known to be a bad estimator, so the probability outputs from `predict_proba` are not to be\n",
    "taken too seriously.\n",
    "\n",
    "### What is a weakness of Bayes Classifier and what can be done against it?\n",
    "\n",
    "- The classifer becomes weak, if a certain state was never observed\n",
    "- Use Laplace Smoothing\n",
    "\n",
    "\n",
    "### Suppose X and Y are two independent Gaussian random variables. Which of the following variable is Gaussian random variable?\n",
    "\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| $4X+3Y$ | ✅ |  |\n",
    "| $X^2$ |  | ❌ |\n",
    "| $X\\cdot Y$ |  | ❌ |\n",
    "| $$ |  | ❌ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870d246",
   "metadata": {},
   "source": [
    "## Decision Tree (classifier)\n",
    "\n",
    "\n",
    "### Early stopping to avoid overfitting and reduce complexity\n",
    "\n",
    "- max. depth of the decision tree\n",
    "- min. number of samples in a leaf node\n",
    "- train until x% of the data is explained\n",
    "- etc.\n",
    "\n",
    "### What are advantages and disadvantages of decision trees?\n",
    "\n",
    "Advantages:\n",
    "- Clear Visualization\n",
    "- Simple and easy to understand\n",
    "- for **classification** and **regression** problems\n",
    "- no feature scaling required\n",
    "- handles non-linearity efficiently\n",
    "- robust to **outliers**\n",
    "- short training preiod (vs. random forrest)\n",
    "\n",
    "Disadvantages:\n",
    "- tends to overfit if no stop condition is defined\n",
    "- high variance in the model and output because of the overfitting issue\n",
    "- instability when regenerating the tree based on new data\n",
    "- affected by **noise** \n",
    "- not suitable for large datasets\n",
    "\n",
    "\n",
    "### How can you improve ... ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f54fe",
   "metadata": {},
   "source": [
    "## Ensemble Methods\n",
    "\n",
    "- _\"What is better than having an ML model - having multiple models!\"_\n",
    "- Take a weak learning algorithm... only requirement should be better than random guessing ... and turn it into a strong one by making it focus on difficult cases.\n",
    "- The error rate of each classifier must be <50% in order for the combined error to decrease.\n",
    "\n",
    "applied to **Classifiers**\n",
    "- taking the majority vote from different classifiers results\n",
    "- theory \n",
    "    + assumes that the classifiers are independent\n",
    "    + Variance reduces linearly\n",
    "    + Bias remains constant\n",
    "- practice\n",
    "    + classifiers are dependent (because of the same training data)\n",
    "    + Variance reduces sub-linearly\n",
    "    + Bias increases slightly\n",
    "\n",
    "applied to **Regression**\n",
    "- **average the results to decrease the standard deviation**\n",
    "- std.dev is reduced by a factor of $\\sqrt{n}$\n",
    "\n",
    "### What is boosting?\n",
    "\n",
    "The multiple models are trained with the data samples that fail to be classified by the previous model.\n",
    "\n",
    "- The 1. model has all of the training data available. This Model has the highest **weight**\n",
    "- the next model has only the difficult cases that are wrongly classified by the previous model to train\n",
    "\n",
    "- randomly sample with replacement over weighted data\n",
    "- **minimizes bias** (and variance) -- fights **underfitting** (and overfitting)\n",
    "\n",
    "### What is bagging (bootstrapping)?\n",
    "\n",
    "(**B**ootstrap + **agg**regation)\n",
    "\n",
    "Train the classifiers with subsets of the original data and repeat some samples (replace).\n",
    "\n",
    "- randomly sample with replacement\n",
    "- **minimizes variance** (usually cannot reduce bias) -- fights **overfitting**!\n",
    "- computational efficient (note: all $M$ models can be trained in parallel)\n",
    "\n",
    "\n",
    "### What is an out of bag error (OOB)?\n",
    "\n",
    "An OOB is an error during the validation with a validation set.\n",
    "\n",
    "From the full dataset there is the training dataset available to train the full Random Forrest Algorithm.\n",
    "The individual sub-trees use again a subsamble from the global training set and a subset for validation (out of bag).\n",
    "An error occurring for one subtree from a validation set is an OOB error.\n",
    "\n",
    "\n",
    "## Random Forrest Classifier\n",
    "\n",
    "- is an ensemble method\n",
    "- RF is not in all situations the best method, however it often simply works\n",
    "\n",
    "\n",
    "- Grow many trees on bootstrapped samples of training data\n",
    "- **Minimize bias** by growing trees sufficiently deep (overfitting)\n",
    "- **Maximize variance reduction** by minimizing correlation between trees by means of bootstrapping data for each tree and sampling variable set at each node (usually $\\sqrt{M}$).\n",
    "- Reduce variance of noisy but **unbiased** trees by averaging\n",
    "\n",
    "Advantages:\n",
    "- Simple -- no assumption of the underlying distribution\n",
    "- OOB error for free\n",
    "- Many variables, even when they are not relevant for the task at hand or noisy\n",
    "- Robust against **outliers**\n",
    "- Multiclass\n",
    "- Limit overfitting (**trees have to be independent**!)\n",
    "- Unbalanced dataset (subsampling)\n",
    "\n",
    "Disadvantages\n",
    "- requires much computational power as well as resources as it builds numerous trees to combine their outputs\n",
    "- requires much time for training as it combines a lot of decision trees to determine the class\n",
    "- due to the ensemble of decision trees, it also **suffers interpretability** \n",
    "- fails to determine the **significance of each variable**\n",
    "\n",
    "### What additional method is used by Random Forest compared to bagging trees.\n",
    "### How does Random Forest relate to decision trees and bagging.\n",
    "\n",
    "The fundamental difference is that in random forests, **only a subset of features are selected at random** out of the total and the best split feature from the subset is used to split each node in a tree, unlike in bagging where all features are considered for splitting a node.\n",
    "\n",
    "### Why are Random Forest robust against outliers?\n",
    "\n",
    "The intuitive answer is that a decision tree works on splits and splits aren't sensitive to outliers: a split only has to fall anywhere between two groups of points to split them. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef190d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Clustering (classification of unlabelled data)\n",
    "\n",
    "The number of clusters:\n",
    "- Parametric-Clustering: k is given\n",
    "- Non-parametric: k determined by algorithm\n",
    "\n",
    "\n",
    "Types of Clustering:\n",
    "- **Hierarchcal Clustering** (HCA) seeks to build a hierarchy of clusters. Strategies for hierarchical clustering generally fall into two types:\n",
    "    + Agglomerative: This is a bottom-up approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.\n",
    "    + Divisive: This is a top-down approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.\n",
    "- **Partitional Clustering**\n",
    "\n",
    "Other Specifications:\n",
    "- Exclusive versus non-exclusive\n",
    "    + In non-exclusive clusterings, points may belong to multiple clusters.\n",
    "    + Can represent multiple classes or ‘border’ points\n",
    "- Fuzzy versus non-fuzzy\n",
    "    + In fuzzy clustering, a point belongs to every cluster with some weight between 0 and 1\n",
    "    + Weights must sum to 1\n",
    "- Probabilistic clustering has similar characteristics\n",
    "    + Partial versus complete\n",
    "    + In some cases, we only want to cluster some of the data\n",
    "- Heterogeneous versus homogeneous\n",
    "    + Clusters of widely different sizes, shapes, and densities\n",
    "\n",
    "\n",
    "### What is the difference between Hard- and Soft Clustering?\n",
    "\n",
    "- **Hard Clustering**: each data point is assigned a unique cluster: Δ\n",
    "- **Soft Clustering**: each data point 𝑖𝑖 is assigned a probability that it is in cluster 𝑘𝑘\n",
    "\n",
    "### Classification vs. Clustering\n",
    "\n",
    "In Classification, the performance of new data (predictions) matters. In Clustering, the given data must be analyzed.\n",
    "In Clustering the number of clusters is to be found by the algorithm (or given). In Classification, the classes are given.\n",
    "\n",
    "### Clustering Metrics\n",
    "\n",
    "- Inertia\n",
    "- NMI: Normalized Mutual Information\n",
    "- BIC: Bayesian Information Criterium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f17132d",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "- Basic agglomerative linkage algorithm\n",
    "- In order to decide which clusters should be combined (for agglomerative), or where a cluster should be split (for divisive), a measure of dissimilarity between sets of observations is required.\n",
    "\n",
    "### Linkage Criteria\n",
    "\n",
    "The linkage criterion determines together with a metric 𝒅(𝒙, 𝒚) when two clusters A and B should be merged together in hierarchical clustering (fusion criterium).\n",
    "\n",
    "- single linkage\n",
    "- complete linkage\n",
    "- average linkage\n",
    "- ward linkage\n",
    "- centroid linkage\n",
    "\n",
    "Comments:\n",
    "- Single linkage tends to generate long “chains”\n",
    "- Complete linkage tends to produce more “compact” clusters\n",
    "- Linkage algorithms are very **vulnerable to outliers**\n",
    "\n",
    "### Distance Matrix\n",
    "\n",
    "\n",
    "<img src=\"images/distance_matrix.png\" width=\"100%\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e57bc8",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "- has a complexity of 𝑶(𝒏)\n",
    "- Cost Function / Loss Function\n",
    "\n",
    "Variants: \n",
    "- k-medoids (centroid to be member of data set)\n",
    "- k-maxoids (for extremes rather than means)\n",
    "\n",
    "### Initialization: Picking Centers\n",
    "\n",
    "- select k data points at random\n",
    "- Initialize the centers using the solution of an even simpler clustering algorithm.\n",
    "- Ideally have prior knowledge, for example that certain points are in different clusters.\n",
    "\n",
    "### What are the basic assumptions of the k-Means algorithm? How does it work? \n",
    "\n",
    "- Each data point is closer to its own cluster center than the other cluster centers\n",
    "- A cluster center is the arithmetic mean of all the points that belong to the cluster.\n",
    "\n",
    "### What are Advantages and Disadvantages of the k-means Clustering?\n",
    "\n",
    "Advantages:\n",
    "- Relatively simple to implement\n",
    "- Scales to large data sets\n",
    "- Guarantees convergence\n",
    "- Can warm-start the positions of centroids\n",
    "- Easily adapts to new examples\n",
    "- Generalizes to clusters of different shapes and sizes, such as elliptical clusters\n",
    "\n",
    "Disadvantages:\n",
    "- K-Means is known as a hard clustering algorithm because clusters are not allowed to overlap\n",
    "- k-means cannot learn the optimal number of clusters from the data. If we ask for six clusters it will find six clusters, which may or may not be meaningful.\n",
    "    + use a more complex clustering algorithm like Gaussian Mixture Models, or one that can choose a suitable number of clusters (DBSCAN, mean-shift, affinity propagation)\n",
    "- k-means is terrible for non-linear data: this results because of the assumption that points will be closer to their own cluster center than others\n",
    "    + transform data into higher dimension where linear separation is possible e.g., spectral clustering\n",
    "- A resulting issue of K-Means' circular boundaries is that it has no way to account for oblong or elliptical clusters.\n",
    "    + 1. measure uncertainty in cluster assignments by comparing distances to all cluster centers\n",
    "    + 2. allow for flexibility in the shape of the cluster boundaries by using ellipses\n",
    "- \n",
    "\n",
    "### What is the k-means++ Algorithm?\n",
    "\n",
    "To avoid the problem of initialization sensitivity: K-Means++ is a smart centroid initialization technique.\n",
    "\n",
    "### How to improve the results of k-means clustering?\n",
    "\n",
    "- Restart many times with different initializations.\n",
    "- Swap individual points between clusters.\n",
    "- Remove a cluster center, and introduce a completely new center instead.\n",
    "- Merge clusters, and additionally introduce a completely new cluster center.\n",
    "- Split a cluster in two pieces (preferably, one which has a very bad objective function). Then reduce the number of clusters again, for example by randomly removing one.\n",
    "\n",
    "### How to pick k (Hyperparameter) ?\n",
    "\n",
    "- **Silhouette Method** (graphical) (Silhouette Plot)\n",
    "- Basic **Elbow Method** \n",
    "- Try range of K values and plot average distance to centers\n",
    "- Silhouette (graphical method, popular in stats)\n",
    "- Cross-Validation (better)\n",
    "- Repeatedly split the data into training and validation datasets\n",
    "- Cluster the training dataset\n",
    "- Measure avg. dist. to centers on validation data\n",
    "- Information theoretic perspective: NMI, BIC and AIC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3867f0",
   "metadata": {},
   "source": [
    "## Density based Clustering - DBSCAN\n",
    "\n",
    "(density-based spatial clustering of applications with noise)\n",
    "\n",
    "- has complexity $O(n^2)$\n",
    "\n",
    "In DBSCAN there are two parameters: `min_samples` and `eps`.\n",
    "If at least min_samples data points are within the distance eps to a given point, this data point is classified as a core object.\n",
    "\n",
    "If less than min_samples points are found within the distance eps --> this point will be classified as noise. \n",
    "\n",
    "**Advantages**\n",
    "− the user **can not set the number of clusters** a priori\n",
    "− DBSCAN is able to capture clusters with **complex shapes**\n",
    "− it identifies points that do not belong to any of the clusters \n",
    "\n",
    "**Disadvantages**\n",
    "- slower than the agglomerative clustering and k-Means, but scales relatively well for large data sets.\n",
    "\n",
    "\n",
    "### DBSCAN vs. k-means\n",
    "\n",
    "- Both are partitional.\n",
    "- K-means is complete; DBSCAN is not.\n",
    "- K-means has a prototype-based notion of a cluster; DB uses a density-based notion.\n",
    "- K-means can find clusters that are not well-separated. DBSCAN will merge clusters that touch.\n",
    "- DBSCAN handles clusters of different shapes and sizes; K-means prefers globular clusters.\n",
    "- DBSCAN can handle noise and outliers; K-means performs poorly in the presence of outliers\n",
    "- K-means can only be applied to data for which a centroid is meaningful; DBSCAN requires a meaningful definition of density\n",
    "- DBSCAN works poorly on high-dimensional data; K-means works well for some types of high-dimensional data\n",
    "- Both techniques were designed for Euclidean data, but extended to other types of data\n",
    "- DBSCAN makes no distribution assumptions; K-means is really assuming spherical Gaussian distributions\n",
    "- K-means has an 𝑂(𝑛) time complexity; DBSCAN is $O(n^2)$\n",
    "- Because of random initialization, the clusters found by K-means can vary from one run to another; DBSCAN always produces the same clusters\n",
    "- DBSCAN automatically determines the number of clusters; K-means does not\n",
    "- K-means has only one parameter, DBSCAN has two. \n",
    "- K-means clustering can be viewed as an optimization problem and as a special case of EM clustering; DBSCAN is not based on a formal model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9055fc3f",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model - GMM\n",
    "\n",
    "- Approximate an arbitrary distribution by a linear combination of a simpler, “well-behaved” distribution\n",
    "- Modeled by a weighted sum of 𝑵 multivariate Gaussians (𝑁 being sufficiently large)\n",
    "- k-means is the EM algorithm for a GMM\n",
    "- In Gaussian Mixture Models (GMM), the 𝛾𝑗 can take on any value between 0 and 1. This is called **soft or fuzzy clustering**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Expectation Maximization - EM\n",
    "\n",
    "### Explain the E- and M-Step of the EM algorithm for probabilistic clustering based on a GMM\n",
    "\n",
    "1. Start with a random initial hypothesis \n",
    "\n",
    "2. **E-Step**: Estimate expected values of unobserved variables, assuming the current hypothesis holds\n",
    "\n",
    "3. **M-Step**: Calculate new Maximum Likelihood (ML) estimate of hypothesis, assuming the expected values from the E-Step hold\n",
    "\n",
    "4. Repeat with step 2 until convergence. Always replacing old estimates with new ones\n",
    "\n",
    "### List a ﬁve data science applications where EM can be used.\n",
    "\n",
    "- Voice Recognition\n",
    "- \n",
    "\n",
    "### explain the loss function that is optimized in case of k-means clustering and how it is derived from probabilistic clustering based on GMM\n",
    "\n",
    "\n",
    "\n",
    "### How would you prove that the EM algorithm converges to the maximum likelihood estimate of the hypothesis made?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc89ae",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Dimensionality Reduction (Decomposition)\n",
    "\n",
    "**Advantages**\n",
    "- It reduces the time and storage space required.\n",
    "- Removal of multi-collinearity improves the interpretation of the parameters of the machine learning model.\n",
    "- It becomes easier to visualize the data when reduced to very low dimensions such as 2D or 3D.\n",
    "- It avoids the curse of dimensionality (e.g. for k-means).\n",
    "\n",
    "\n",
    "### Explain what Sparsity in data is and how it is related to dimensionality reduction\n",
    "\n",
    "[Sparsity] = [Seltenheit]\n",
    "\n",
    "[parsimonious] = [selten, sparsam, geizig, knauserig]\n",
    "\n",
    "Natural data tends to be sparse even in high dimensional spaces.\n",
    "This means that even with many features (high dimension) the data only ever takes on very distinct patterns that can be \n",
    "\n",
    "> If natural data is expressed in a well-chosen basis, only a few parameters are \n",
    "required to characterize the modes that are active, and in what proportion.\n",
    "\n",
    "Therefore, a lot of data is unnecessary which helps to use **parsimonious models** (which use much less features) that **avoid overfitting** and remain **interpretable**.\n",
    "\n",
    "> **Sparse optimization** is also useful for adding robustness with respect to outliers and missing \n",
    "data, which generally skew the results of least-squares regression, such as the SVD.\n",
    "\n",
    "### Feature Reduction & Feature Extraction\n",
    "\n",
    "Feature **Extraction**: transforms the data in the high-dimensional space to a space of fewer dimensions\n",
    "\n",
    "Feature **Reduction**: approaches try to find a subset of the original variables (also called features or \n",
    "attributes). There are three strategies: \n",
    "- the **filter** strategy\n",
    "    + information gain, chi-square test\n",
    "    + fisher score, correlation coefficient\n",
    "- the **wrapper** strategy (e.g. search guided by accuracy): \n",
    "    + recursive feature elimination\n",
    "    + sequential feature selection algorithms, genetic algorithms\n",
    "- the **embedded strategy** (features are selected to add or be removed while building the model based on the prediction errors).\n",
    "    + Lasso (L1 regularization)\n",
    "    + Decision tree\n",
    "\n",
    "### What is the Law of large Numbers?\n",
    "\n",
    "But there are also blessings for high dimensional spaces:\n",
    "\n",
    "- The most well known example is the Law of Large Numbers, which says in a nutshell that the sum of independent, identically distributed scalar-valued random variables is approximately normal distributed.\n",
    "\n",
    "\n",
    "### What is the Manifold Hypothesis?\n",
    "\n",
    "> The Manifold Hypothesis states that real-world high-dimensional data lie on low-dimensional manifolds embedded within the high-dimensional space.\n",
    "\n",
    "- features lie on a subspace\n",
    "- (using one hot encoding)\n",
    "\n",
    "> A collection of methodologies for analyzing high dimensional data based on the hypothesis that data tend to lie near a low dimensional manifold is now called Manifold Learning.\n",
    "\n",
    "\n",
    "### Which Dimensionality Reduction Algorithms do you know?\n",
    "\n",
    "- Principal Component Analysis (PCA)\n",
    "    + PCA (linear)\n",
    "    + Kernel PCA (non-linear)\n",
    "- Manifold Methods based on similarity\n",
    "    + MDS: Multidimensional scaling\n",
    "    + LLE: local linear embedding\n",
    "    + Isomap: Isometric mapping\n",
    "    + t-SNE: t-distributed stochastic neighbor embedding\n",
    "\n",
    "<img src=\"images/featurereduction.png\" width=\"80%\"/>\n",
    "\n",
    "### Thinking about dimensionality reduction and attribute selection, which ones of the following statements are true (multiple choice) ?\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| Wrapper methods usually provide the best performing feature set for a particular type of model. However, they are computationally intensive since for each subset a new model needs to be trained. | ✅ |  |\n",
    "| Filter methods are independent to the type of predictive model. Common measures are distance metrics, correlation, mutual information, and consistency metrics. | ✅ |  |\n",
    "| Wrappers are feature selection methods that, given a classifer as a performance criteria, search in the space of subset of features (feature combinations) for the minimal one that obtains the higher accuracy. | ✅ |  |\n",
    "| Filters are unsupervised feature selection methods because they use evaluation criteria from the intrinsic connections between features to score a feature subset. | ✅ |  |\n",
    "\n",
    "\n",
    "### Which dimensionality reduction algorithm do you know?\n",
    "\n",
    "- **Kernel PCA** is generally well suited in reducing the dimensionality of high dimensional, nonlinear datasets. By applying the kernel trick, a nonlinear mapping is applied to the input data, actually increasing the dimensionality even more. The kernel however can be evaluated in dataspace. The problem complexity is given by the number of data points.\n",
    "- **Local Linear Embedding (LLE)** reduces dimensionality while trying to preserve the distances between close instances only.\n",
    "- **Isomap** creates a graph by connecting each instance to its nearest neighbors, then reduces dimensionality while trying to preserve the geodesic distances between the instances.\n",
    "- **t-Distributed Stochastic Neighbor Embedding (t-SNE)** reduces dimensionality while trying to keep similar instances close and dissimilar instances apart. It is mostly used for visualization, in particular to visualize clusters of instances in high-dimensional space (e.g., to visualize the MNIST images in 2D).\n",
    "- **Linear Discriminant Analysis (LDA)** is actually a classiﬁcation algorithm. During training it learns the most discriminative axes between the classes. These axes can be used to deﬁne a hyperplane onto which to project the data. The projection will keep classes as far apart as possible, so LDA is a good technique to reduce dimensionality before running another classiﬁcation algorithm such as an SVM classiﬁer.\n",
    "\n",
    "### How can you evaluate the performance of a dimensionality reduction algorithm?\n",
    "\n",
    "(general question)\n",
    "\n",
    "One way to measure the performance of the reduction alone is to apply the reverse transformation and measure the reconstruction error. This only works, if an inverse can be aplied.\n",
    "\n",
    "It depends on what performance measurement the entire machine learning task optimizes for. In order for this question to be answered, a performence metric must also be defined (e.g. \n",
    "Average Precision, Precision, Recall, f1-score etc.)\n",
    "\n",
    "What is the f1-score?\n",
    "- combines Precision and Recall into a single number\n",
    "\n",
    "Recall vs. Precision\n",
    "- Depends on what you optimize for.\n",
    "- Optimization Goal should be a single number.\n",
    "\n",
    "### Does it make sense to chain two different dimensionality reduction algorithms?\n",
    "\n",
    "(general question)\n",
    "\n",
    "It depends on the task. It could help to increase the speed.\n",
    "\n",
    "> A common example is using PCA to quickly get rid of a large number of useless dimensions, then applying another much slower dimensionality reduction algorithm, such as LLE. This two-step approach will likely yield the same performance as using LLE only, but in a fraction of the time.\n",
    "\n",
    "### What are the main motivations for reducing a dataset’s dimensionality?\n",
    "\n",
    "- noise reduction, removal\n",
    "- removal of noise and redundant features for classiﬁcation tasks\n",
    "- algorithms perform better and faster with less dimensions\n",
    "- removes redundant features\n",
    "- allows to filter for features that matter and discard features that have no additional information\n",
    "- visualization of high dimensional data\n",
    "- data compression\n",
    "\n",
    "### What are the main drawbacks of dimensionality reduction techniques?\n",
    "\n",
    "- information is lost on purpose\n",
    "- linear methods are not able to unwrap / detect substructures\n",
    "- the reduction process is again a step in the machine learning chain that uses processing power and time\n",
    "- adds complexity to the leaerning pipeline\n",
    "- transformed spaces are hard to interpret by humans\n",
    "\n",
    "### Once a dataset’s dimensionality has been reduced, is it possible to reverse the operation? If so, how? If not, why?\n",
    "\n",
    "(general question)\n",
    "\n",
    "For some methods **yes**. The data can be decompressed but will be contaminated with some artifacts because some information was lost.\n",
    "\n",
    "Also, not all methods have an inverse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c59b0",
   "metadata": {},
   "source": [
    "## PCA - Principle Component Analysis\n",
    "\n",
    "- The main linear technique for dimensionality reduction, principal component analysis PCA, performs a linear mapping of the data to a lower-dimensional space in such a way that the **variance** of the data in the lowdimensional representation **is maximized**.\n",
    "\n",
    "- The eigen vectors that correspond to the largest eigenvalues (the principal components) can now be used to reconstruct a large fraction of the variance of the original data. \n",
    "\n",
    "- PCA identifies the 𝒌-dimensional hyperplane that lies closest to the data and then projects the data on it. (𝑘 is a hyperparameter).\n",
    "\n",
    "- PCA is a **rotation** (or reflection) so that the first principal component (PC) has the highest variance, the second is orthogonal to the first and has the second highest variance, ... 𝑋 is the (𝑛 × 𝑑) −dimensional data matrix column centered.\n",
    "\n",
    "- PCA minimizes the **reconstruction error** over all m available data points.\n",
    "\n",
    "**Applications**\n",
    "- Dimensionality reduction as a preprocessing step for other learning algorithms or analysis steps (e.g. face detection & recognition)\n",
    "- Revovering data manifolds: finding affine data manifolds\n",
    "- Data visualization and exploration by plotting data in low-dimensional space\n",
    "- Data denoising and reconstruction\n",
    "\n",
    "**Limitations**\n",
    "- Linearity --> nonlinear and kernel PCA\n",
    "- Uncorrelated is not independent --> ICA = Independent Component Analysis\n",
    "- Probabilistic model / interpretation --> probabilistic PCA\n",
    "- Least squares approx. maybe inappropriate --> probabilistic Latent Semantic Analysis (pLSA)\n",
    "- Constraints on sign of loadings --> nonnegative matrix decomposition\n",
    "\n",
    "### Explained Variance Ratio 𝑷𝒌\n",
    "\n",
    "- **No data is lost** in that transformation. The first component explains most of the variance, ... All components explain the whole variance. \n",
    "- Now take only a few components (the first 𝒌) and hope that data is explained by them.\n",
    "- How good is the approximation? A measure is the explained variance ratio: the percentage of the first 𝑘𝑘 dimensions contribute to the variance (their importance).\n",
    "\n",
    "Max{variance} = min{reconstruction error}\n",
    "\n",
    "### Can PCA be used to reduce the dimensionality of a highly nonlinear dataset? Which methods can alternatively be used?\n",
    "\n",
    "No, PCA/NDS acts globally.\n",
    "\n",
    "Use a Kernel instead. \n",
    "\n",
    "> If highly nonlinear distribution, which would you select ( ... ) ?\n",
    "\n",
    "###  Suppose you perform a PCA on a 1000-dimensional dataset, setting the explained variance to 95%. How many dimensions will the resulting dataset have?\n",
    "\n",
    "(general question)\n",
    "\n",
    "cannot be answered. depends on data\n",
    "\n",
    "### In which cases would you use incremental PCA, randomized PCA or kernel PCA?\n",
    "\n",
    "\n",
    "- **Randomized PCA** is useful when you want to considerably reduce dimensionality and the dataset ﬁts in memory; in this case, it is much faster than regular PCA. Finally, Kernel PCA is useful for nonlinear datasets.\n",
    "- **Randomized PCA** to save computation time by selecting a randomized subset of the data. \n",
    "- **kernel PCA** is used for nonlinear datasets\n",
    "- **Regular PCA** is the default, but it works only if the dataset ﬁts in memory.\n",
    "- **Incremental PCA** is useful for large datasets that don’t ﬁt in memory, but it is slower than regular PCA, so if the dataset ﬁts in memory you should prefer regular PCA. Incremental PCA is also useful for online tasks, when you need to apply PCA on the ﬂy, every time a new instance arrives.\n",
    "\n",
    "\n",
    "### Which similarity methods do you know?\n",
    "\n",
    "- Multidimensional Scaling (**MDS**)\n",
    "- Local Linear Embedding (**LLE**)\n",
    "- Isometric Mapping (**Isomap**)\n",
    "- t-distributed Stochastic Neighbor Embedding (t-SNE, **tSNE**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ae5f1",
   "metadata": {},
   "source": [
    "## Kernel Functions - Kernel PCA (KPCA)\n",
    "\n",
    "### High-dimensional mapping can seriously increase computation time. Can we get around this problem and still get the benefit of high-D? \n",
    "\n",
    "YES: using the Kernel-Trick:\n",
    "\n",
    "Given any algorithm that can be expressed solely in terms of **dot products**, this trick allows us to construct different nonlinear versions of it.\n",
    "\n",
    "1. Mapping into a nonlinear feature space\n",
    "2. Extract the PCA in that space (the result will be nonlinear in the original data space)\n",
    "\n",
    "### List four commonly used kernels $k(x, x′)$ in Machine Learning.\n",
    "\n",
    "- Gaussian Radial Basis Function (RBF) $K(x,x')=exp(-\\beta\\cdot||x-x'||^2)$\n",
    "- Laplacian $K(x,x')=exp(-\\gamma|x-x'|_1)$\n",
    "- Polynomial $K(x,x')=(1+x^Tx')^p$\n",
    "- Sigmoid $K(x,x')=tanh(\\alpha x^T x'+\\sigma)$\n",
    "- Linear Kernel $K(x,x')=x^T x'$\n",
    "\n",
    "\n",
    "### Show, that the RBS-kernel is symmetric and positive semi-deﬁnite.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585f946c",
   "metadata": {},
   "source": [
    "## Multi Dimensional Scaling - MDS\n",
    "\n",
    "### Classical MDS = Principal Coordinates Analysis (PCoA) \n",
    "\n",
    "MDS attempts to model similarity or dissimilarity \n",
    "data as distances in a geometric spaces.\n",
    "\n",
    "MDS attempts to find an embedding from the high dimensional objects in 𝑰 into 𝒚𝒊 ∈ ℝ𝒅 such that **distances 𝒅𝒊 are preserved**\n",
    "\n",
    "- For Euclidean distances, classical MDS is equivalent to PCA (but conceptually different)\n",
    "- MDS tries to preserve the distance between all data points, even if they are far separated \n",
    "- **LLE** only preserves distance between nearby points and is often able to map complex structures to low dimensions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Local Linear Embedding - LLE\n",
    "\n",
    "LLE describes **the local properties of the manifold around a data point** 𝑥𝑖 by writing the data point as a linear combination (the so-called reconstruction weights 𝑤𝑖𝑗) of its 𝑘 nearest neighbors\n",
    "\n",
    "In the low dimension, LLE attempts to **retain the reconstruction weights 𝑾** as well as possible. Hence, LLE fits a hyperplane through the data point 𝑥𝑖 and its nearest neighbors, thereby **assuming that the manifold is locally linear**.\n",
    "\n",
    "\n",
    "## Isomap\n",
    "\n",
    "- A **nonlinear** method for dimensionality reduction\n",
    "- Finds the map that preserves the global, nonlinear geometry of the data by **preserving the geodesic manifold interpoint distances**\n",
    "\n",
    "(Geodesic Distance follows the data density instead of shortest path)\n",
    "\n",
    "\n",
    "**Advantages**\n",
    "- Nonlinear\n",
    "- Non-iterative\n",
    "- Globally optimal\n",
    "- Parameters: k or ε (chosen fixed radius)\n",
    "\n",
    "**Disadvantages**\n",
    "- Graph discreteness overestimates the geodesic distance\n",
    "- **k must be high** to avoid “linear shortcuts” near regions of high surface curvature\n",
    "\n",
    "\n",
    "## t-SNE (tSNE)\n",
    "\n",
    "- Is well suited for the **visualization** of high-dimensional datasets.\n",
    "- t-SNE uses a **tuneable parameter**, “perplexity,” which says (loosely) how to balance attention between local and global aspects of your data. The parameter is, in a sense, a guess about the number of close neighbors each point has\n",
    "- t-SNE is incredibly **flexible, and can often find structure where other dimensionality-reduction algorithms cannot**. Unfortunately, that very flexibility makes it tricky to interpret.\n",
    "\n",
    "### SNE algorithm\n",
    "\n",
    "constructs a probability distribution 𝑝 over the dataset X, and then another probability distribution 𝑞 in a lower dimensional data space Y, making both the distribution as “close” as possible.\n",
    "\n",
    "The goal is to make sure the two probability distributions are as similar as possible. This is achieved by considering the Kullback-Leibler (KL) divergence. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a29c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Training & Validation\n",
    "\n",
    "\n",
    "### Debugging Questions\n",
    "\n",
    "Suppose you are using some classiﬁer algorithm on a given training set. The training error\n",
    "is acceptable. However, it makes unacceptably large errors in its predictions on unseen data.\n",
    "What should be tried next?\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| Get more training samples. | ✅ |  |\n",
    "| Try larger sets of features, e.g. by generating polynomial features. |  | ❌ |\n",
    "| Decrease the regularization parameter λ if regularization is used.  |  | ❌ |\n",
    "| Create a meta learner, e.g. a voting or bagging classiﬁer out of several diﬀerent classiﬁers or build an ensemble of classiﬁers. | ✅ |  |\n",
    "\n",
    "### Validation Curve\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| A validation curve shows the training error as function of the training data size. |  | ❌ |\n",
    "| A validation curve shows the training error as function of the hyperparameter. | ✅ |  |\n",
    "| If the learning curve shows a large gap between training and test error, the learner most probably suﬀers from a high bias problem. |  | ❌ |\n",
    "| If the learning curve shows a large gap between training and test error, the learner most probably suﬀers from a high variance problem. | ✅ |  |\n",
    "| Hyperparameter tuning shoud be done using a cross-validated grid search within the inner loop. | ✅ |  |\n",
    "|  In a Bayesian approach, the hyperparameters can be deﬁned by a prior distribution. Using Bayes theorem to calculate the posterior, we get a point estimate of the hyperparameters. |  | ❌ |\n",
    "\n",
    "If performance overall is bad (20%) in the learning curve, it is an indication of **high bias**\n",
    "\n",
    "### Estimation Error\n",
    "\n",
    "Thinking about the estimation error with the training set for a learning method. Which of the\n",
    "following statements are true? (multiple answer)\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| The estimation error of the decision tree built for the training set without pruning on the trainng data is zero. | ✅ |  |\n",
    "| The estimation error for the training set for the built 3-KNN classiﬁer with this data is zero. |  | ❌ |\n",
    "| The estimation error for the training set in the decision tree constructed with this data after the pruning procedure is zero. |  | ❌ |\n",
    "| The estimation error for the training set for the built 1-KNN classiﬁer with this is zero. | ✅ |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adabcba",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "1. Split Data into Training and Test data\n",
    "2. Training Data + Cross-Validation -> best Hyperparameters\n",
    "3. Retrain model with best Hyperparameters on the entire Training Data\n",
    "4. Test Data + Model -> estimate of generalization error\n",
    "\n",
    "Note: The estimate of the generalization error can be cross-validated as well\n",
    "\n",
    "Advantages:\n",
    "- make to most out of the examples!\n",
    "- averages out do individual performance of the splits (especially for few data-points)\n",
    "\n",
    "Types of Validaton:\n",
    "- 2-fold cross-validation \n",
    "- k-fold cross-validation \n",
    "- LOOCV (leave-one-out-...)\n",
    "\n",
    "### The numerical complexity of $k$-fold crossvalidation is...\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| linear in $k$ | ✅ |  |\n",
    "| quadratic in $k$ |  | ❌ |\n",
    "| cubic in $k$ |  | ❌ |\n",
    "| exponential in $k$ |  | ❌ |\n",
    "\n",
    "\n",
    "## Validation Curve\n",
    "\n",
    "\n",
    "\n",
    "## Hyper Parameter Tuning\n",
    "\n",
    "### How do you tune hyper parameters?\n",
    "\n",
    "- use grid search (linear or logarithmic step sizes)\n",
    "\n",
    "### What are disadvantages of grid search?\n",
    "\n",
    "- Smaller step size corresponds to more scenarios to be tested which increases the training time\n",
    "- additional hyperparameters increase the effort exponentially\n",
    "- with large step sizes there is the risk to end up in a local maxima/minima and miss the global optimum\n",
    "\n",
    "### What does grid search optimize?\n",
    "(general question)\n",
    "\n",
    "It depends on what the overall algorithm wants to achieve. So a metric must be selected (e.g. Accuracy Score, Precision, f1-Score etc.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8675f457",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Advantages\n",
    "\n",
    "Disadvantages\n",
    "\n",
    "\n",
    "### What are different methods to apply parameter tuning?\n",
    "\n",
    "- Grid-Search\n",
    "- Random-Search\n",
    "- Optimization\n",
    "    + Gradient Descent\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde76f6",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Regression\n",
    "\n",
    "### Regularization for regression\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "|  LASSO regularization uses the L2 norm of the vector of parameters to be estimated. |  | ❌ |\n",
    "|  LASSO regularization can be used for feature selection, because it forces a spase output where some parameters are set to zero.  | ✅ |  |\n",
    "| Regularization for for any learner can be done by adding a penalty to the cost (loss) function that penalizes too complex models. | ✅ |  |\n",
    "| The parameter etimates for ridge regression can be calculated directy using an analytical solution. | ✅ |  |\n",
    "\n",
    "### Which of the following statements about regularization and the regularization parameter λ are correct ?\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| Using too large a value of λ can cause your hypothesis to underﬁt the data. | ✅ |  |\n",
    "|  Using too large a value of λ can cause your hypothesis to overﬁt the data.  |  | ❌ |\n",
    "| Using a very large value of λ cannot hurt the performance of your hypothesis. |  | ❌ |\n",
    "| None of the above.  |  | ❌ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4690d2c",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "1. Forward Propagation \n",
    "2. Calculate Loss (Error)\n",
    "3. Backward Propagation (Gradient)\n",
    "4. Apply Gradient Descent\n",
    "5. Repeat until convergence\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "We only need the gradient of the Loss function with respect to every parameter\n",
    "\n",
    "Logistic Regression Loss\n",
    "\n",
    "Problems:\n",
    "- local minima\n",
    "\n",
    "\n",
    "Max Likelihood\n",
    "\n",
    "### Deep Learning\n",
    "\n",
    "When **Big Data** is available, **Neural Networks** perform better than classical Machine Learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32980d",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb7771",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Reinforcement Learning \n",
    "\n",
    "There are many iterative methods for large MRPs, e.g.\n",
    "- Value-Iteration / Policy-Iteration\n",
    "- Temporal-Difference learning\n",
    "    + Value Iteration\n",
    "    + Q-learning\n",
    "\n",
    "Model free (time difference) methods: \n",
    "- value iteration\n",
    "- Q-learning\n",
    "\n",
    "> - Reinforcement learning involves an agent, a set of states 𝑆, and a set 𝐴 of actions per state. By \n",
    "performing an action 𝑎 ∈ 𝐴, the agent transitions from state $s_t$ to state $s_{t+1}$. Executing an action in \n",
    "a specific state provides the agent with a **reward** ℛ (a numerical score).\n",
    "> - The goal of the agent is to **maximize its total (future) reward**.\n",
    "> - This potential reward is a weighted sum of the expected values of the rewards of all future steps \n",
    "starting from the current state.\n",
    "\n",
    "### What is the definition of a _finite Markov decision process_ (MDP)?\n",
    "\n",
    "> - A Markov process is a memoryless random process, i.e. a sequence of random states $s_1$, $s_2$, ... with \n",
    "the **Markov property**.\n",
    "\n",
    "> A **Markov Process** (or Markov Chain) is a tuple 𝑆𝑆, 𝑃𝑃 , where \n",
    "> - 𝑆 is a (finite) set of states\n",
    "> - 𝑃 is a state transition probability matrix: $P_{ss'} = \\mathrm{Pr}(s_{t+1}|s_t)$\n",
    "\n",
    "> - The next state $s_{t+1}$ depends on the current state $s_t$ and the decision maker's action 𝑎. But given \n",
    "$s_t$ and 𝑎, $s_{t+1}$ is **conditionally independent of all previous states and actions**\n",
    "> - in other words, the state transitions of an MDP satisfies the Markov property, it is a \n",
    "memoryless process\n",
    "\n",
    "> A **Markov Decision Process** is a tuple (𝑆, 𝐴, 𝑃, ℛ, 𝛾)\n",
    "> - 𝑆 is a (finite) set of states\n",
    "> - **A is a (finite) set of actions**\n",
    "> - 𝑃 is a state transition probability matrix: $P=P_{ss'} = \\mathrm{Pr}(s_{t+1}|s_t)$\n",
    "\n",
    "### What is the definition of a _Markov reward process_ (MRP)?\n",
    "\n",
    "A Markov reward process is a stochastic process which extends either a Markov chain or continuous-time Markov chain by adding a **reward rate** to each state. **An additional variable records the reward accumulated** up to the current time.\n",
    "\n",
    "> A **Markov Reward Process** is a tuple (𝑆, 𝐴, 𝑃, ℛ, 𝛾)\n",
    "> - 𝑆 is a (finite) set of states\n",
    "> - **A is a (finite) set of actions**\n",
    "> - 𝑃 is a state transition probability matrix: $P=P_{ss'} = \\mathrm{Pr}(s_{t+1}|s_t)$\n",
    "> - **ℛ is a reward function** (expectation value of the next reward): \n",
    "> - 𝛾 is a discount factor: 𝛾 ∈ [0, 1]\n",
    "\n",
    "### Why discount the Markov Process with $\\gamma < 1$?\n",
    "\n",
    "- 𝛾 close to 0 leads to \"myopic\" evaluation\n",
    "- 𝛾 close to 1 leads to \"far-sighted\" evaluation\n",
    "\n",
    "- Mathematically convenient to discount rewards (convergence, contraction property of the Bellmann operator leads to a single fixpoint)\n",
    "- Avoids infinite returns in cyclic Markov processes\n",
    "- Uncertainty about the future may not be fully represented.\n",
    "- If the reward is financial, immediate rewards may earn more interest than delayed rewards.\n",
    "- Animal/human behavior shows preference for immediate reward.\n",
    "- It is sometimes possible to use undiscounted Markov reward processes (i.e. 𝛾 = 1), e.g. **if all sequences terminate**\n",
    "\n",
    "### Value Function 𝑉(𝑠) and Bellman Equation for MRP\n",
    "\n",
    "The value function 𝑉(𝑠) gives the **expected long-term value of state 𝑠** (state value function)\n",
    "\n",
    "- Computational complexity is $O(n^3)$ for 𝑛 states\n",
    "- The standard approach to “solve” MDPs is to use dynamic programming, which transforms the problem of finding a good controller into the problem of finding a good value function. \n",
    "\n",
    "> Bellman’s principle of optimality: in many mathematical optimization problems, the optimum \n",
    "(global) solution is a sequence of optimum partial solutions:\n",
    "\n",
    "### Dynamic Programming (DP)\n",
    "\n",
    "> Dynamic programming (DP) breaks a multi-period planning problem into simpler steps at \n",
    "different points in time 𝑡. Therefore, it **requires keeping track of the states $s_t$**. The DP approach \n",
    "**describes the optimal plan by finding a rule (policy 𝜋)** that tells what the **actions 𝑎** should be \n",
    "taken, given any possible value of the state 𝑠.\n",
    "\n",
    "There are two necessary conditions a problem must satisfy for DP to work.\n",
    "\n",
    "- **Overlapping**, i.e. repeating sub-problems: A sub-problem is simply a smaller version of the problem at hand. e.g. recursice functions and divide and conquer (DAC) algorithms.\n",
    "- **Optimal substructure**: optimal solutions to sub-problems can directly be considered when computed the overall optimal solution\n",
    "\n",
    "\n",
    "### What is Q-learning?\n",
    "\n",
    "In Q-learning, **the agent does not know state transition probabilities or rewards**. The agent only discovers that there is a reward for going from one state to another via a given action when it does so and receives a reward. \n",
    "\n",
    "When you're designing a system, you know exactly how rewards and state transitions are set up. But you never tell the agent any of this - instead you force it to learn on its own through trial and error. This is **important if you want to create an agent that is capable of entering a new situation** that you don't have any prior knowledge about and figuring out what to do. Alternately, if you don't care about the agent's ability to learn on its own, **Q-learning might also be necessary if the state-space is too large to repeatedly enumerate**. Having the agent explore without any starting knowledge can be more computationally tractable.\n",
    "\n",
    "### What is Value Iteration?\n",
    "\n",
    "Value iteration is used when you have transition probabilities, that means when you know the probability of getting from state x into state x' with action a.\n",
    "\n",
    "- A policy fully defines the behaviour of an agent\n",
    "- MDP policies depend on the current state (not the history\n",
    "- policies are stationary (time-independent)\n",
    "- The state-value-function $V(s)$ is the expected return starting from state 𝑠𝑠, and then following any policy 𝜋\n",
    "\n",
    "\n",
    "### the diﬀerence between on-policy and oﬀ-policy learning.\n",
    "\n",
    "\n",
    "**On-policy** methods attempt to evaluate or improve the policy that is used to make decisions. In contrast, **off-policy** methods evaluate or improve a policy different from that used to generate the data.\n",
    "\n",
    "**Off-policy** is independent of the agent’s actions. It figures out the optimal policy regardless of the agent’s motivation. \n",
    "\n",
    "The reason that **Q-learning is off-policy** is that it updates its Q-values using the Q-value of the next state s′ and the greedy action a′. In other words, it estimates the return (total discounted future reward) for state-action pairs **assuming a greedy policy were followed despite the fact that it's not following a greedy policy**.\n",
    "\n",
    "The reason that **SARSA is on-policy** is that it updates its Q-values using the Q-value of the next state s′\n",
    "and the current policy's action a′′. It estimates the return for state-action pairs **assuming the current policy continues to be followed.**\n",
    "\n",
    "\n",
    "### explain the diﬀerence between value iteration and policy iteration.\n",
    "\n",
    "- **Policy iteration** includes: **policy evaluation + policy improvement**, and the two are repeated iteratively until policy converges.\n",
    "- **Value iteration** includes: finding **optimal value function** + one **policy extraction**. There is no repeat of the two because once the value function is optimal, then the policy out of it should also be optimal (i.e. converged).\n",
    "\n",
    "### The trade-oﬀ between exploitation and exploration.\n",
    "\n",
    "**Exploitation**: To use the Q-table as a reference and view all possible \n",
    "actions for a given state. The agent then **selects the action based on the max value** of \n",
    "those actions. This is known as exploiting since we use the information we have \n",
    "available to us to make a decision.\n",
    "\n",
    "**Exploration**: The second way to take action is to **act randomly**. \n",
    "Instead of selecting actions based on the max future reward we select an action at random. Acting randomly is important because it allows the agent to explore and discover new states that otherwise may not be selected during the exploitation \n",
    "process. \n",
    "\n",
    "**𝜺−greedy policy**: You can balance exploration/exploitation using epsilon (𝜀) as the \n",
    "probability to explore instead of exploit. \n",
    "\n",
    "### Reinforcement learning vs. state space search\n",
    "\n",
    "**Search**\n",
    "- State is fully known\n",
    "- **actions are deterministic**\n",
    "- **find a goal state**\n",
    "    + **finite horizon**\n",
    "- find **plan** to reach goal state\n",
    "\n",
    "**RL**\n",
    "- State is fully known\n",
    "- **actions have random outcomes**\n",
    "- **maximize reward**\n",
    "    + **infinite** horizon\n",
    "- find **policy** for what to do in each state\n",
    "\n",
    "### Is the MDP framework adequate to usefully represent all goal-directed learning tasks? Can you think of any clear exceptions?\n",
    "\n",
    "\n",
    "### Discount Factor $\\gamma$\n",
    "\n",
    "The discount factor essentially determines how much the reinforcement learning agents cares about \n",
    "rewards in the distant future relative to those in the immediate future.  \n",
    "\n",
    "### What is SARSA?\n",
    "\n",
    "SARSA (state-action-reward-state-action) is an on-policy reinforcement learning algorithm that estimates the value of the policy being followed. In this algorithm, the agent grasps the optimal policy and uses the same to act. The policy that is used for updating and the policy used for acting is the same, unlike in Q-learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9482b303",
   "metadata": {},
   "source": [
    "## Maximum Likelihood\n",
    "\n",
    "\n",
    "### The maximum likelihood model parameters $\\alpha$ can be learned using linear regression for the model: $y_i=\\alpha_1 x_1 x_2^3+\\epsilon_i$ where $\\epsilon_i \\approx N(0,\\sigma^2)$ iid noise.\n",
    "\n",
    "This is true. $y$ is linear in $\\alpha_1$, so it can be learned using linear regression.\n",
    "\n",
    "### The maximum likelihood model parameters $\\alpha$ can be learned using linear regression for the model: $y_i=x_1 ^{\\alpha_1} \\cdot e^{\\alpha_2}+\\epsilon_i$ where $\\epsilon_i \\approx N(0,\\sigma^2)$ iid noise.\n",
    "\n",
    "This is false. $y$ is not linear in $\\alpha_1$ and $\\alpha_2$, and no simple transformation will make it linear\n",
    "($\\log [x^{\\alpha_1} \\cdot e^{\\alpha_2} +\\epsilon_i] \\neq \\alpha_1 \\log x_1 + alpha_2 + \\epsilon_i$).\n",
    "\n",
    "### You are a reviewer for the International Mega-Conference on Algorithms for Radical Learning of Outrageous Stuﬀ, and you read papers with the following experimental setups.\n",
    "\n",
    "> My algorithm is better than yours. Look at the training error rates!\n",
    "\n",
    "Would you accept or reject each paper? Provide a one sentence justiﬁcation. (This conference has short reviews.)\n",
    "\n",
    "- Reject - the training error is optimistically biased.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844053da",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Probabilistic Reasoning (Bayes)\n",
    "\n",
    "You can name the prior probability distribution, the likelihood function, the \n",
    "evidence, and you know how to marginalize over a joint probability distribution.\n",
    "\n",
    "you know the basic properties of a multivariate Gaussian probability distribution. \n",
    "\n",
    "kernel density estimation method.\n",
    "\n",
    "Probabilities are independent if: $p(A,B) = p(A)\\cdot p(B)$\n",
    "\n",
    "### Bayes Rule & Marginalization\n",
    "\n",
    "$$\n",
    "p(Y|X) = \\frac{p(X|Y)\\cdot p(Y)}{p(X)} = \\frac{p(X|Y)\\cdot p(Y)}{ \\sum_y p(X|y)\\cdot p(y) }\n",
    "$$\n",
    "\n",
    "\n",
    "### What is the difference between a joint and a conditional probability distribution\n",
    "\n",
    "- **Joint** probability is the probability of two events occurring **simultaneously**.\n",
    "- **Marginal** probability is the probability of an event irrespective of the outcome of another variable.\n",
    "- **Conditional** probability is the probability of one event occurring in the presence of a second event.\n",
    "\n",
    "Conditional Probability:\n",
    "- Probability of Outcome $Y$ given Event $X$ --> $p(Y|X)$\n",
    "\n",
    "Joint Probability: --> $p(X,Y)$\n",
    "\n",
    "\n",
    "### What is the Mahalanobis Distance?\n",
    "\n",
    "The Mahalanobis distance is a measure of the **distance between a point P and a distribution D**. It is a **multidimensional** generalization of the idea of measuring **how many standard deviations away P is from the mean of D**. This distance is zero for P at the mean of D and grows as P moves away from the mean along each principal component axis.\n",
    "\n",
    "It is part of the **multivariate Gaussian distribution**.\n",
    "\n",
    "\n",
    "### Explain \"regression toward the mean\"\n",
    "\n",
    "The phenomenon that arises if a sample point of a random variable is extreme (nearly an outlier), a future point is likely to be closer to the mean or average.\n",
    "\n",
    "\n",
    "\n",
    "### Which model learns joint probability?\n",
    "\n",
    "\n",
    "### Which model learns conditional probability?\n",
    "\n",
    "\n",
    "\n",
    "### Marginalization Formula\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139a318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
