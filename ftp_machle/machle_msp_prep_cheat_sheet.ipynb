{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb89e69d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left\"> <b> Machine Learning </b> <br> MSE FTP MachLe <br> \n",
    "<a href=\"mailto:simon.burkhardt@fhnw.ch\"> Simon Burkhardt </a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efae1e",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "FS2021 - Examp Preparaion Notes / Cheat Sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99416685",
   "metadata": {},
   "source": [
    "#### How to use this sheet?\n",
    "\n",
    "> This is a collection of the most important Machine Learning facts gathered in a form to quickly find information during an exam.\n",
    "> Use `CTRL+F` during the exam to search for the topic that you are working on or to answer an question.\n",
    "\n",
    "> for general questions answer with:\n",
    ">- \"It depends ... \"\n",
    ">- \"In the case of ... I would do ...\"\n",
    "\n",
    "\n",
    "---\n",
    "this sheet is WIP\n",
    "\n",
    "**current todos**\n",
    "\n",
    "Ensemble methods\n",
    "\n",
    "Which model learns joint probability?\n",
    "\n",
    "Which model learns conditional probability?\n",
    "\n",
    "Which model is more sensitive to outliers?\n",
    "\n",
    "Which models can generate data from learned data?\n",
    "\n",
    "Which models can complete missing values in a dataset?\n",
    "\n",
    "What is recall?\n",
    "\n",
    "What is the f1-score?\n",
    "\n",
    "Regularization for Regression & regularization parameter λ\n",
    "\n",
    "https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/\n",
    "\n",
    "https://en.wikipedia.org/wiki/Mahalanobis_distance\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe6f3d",
   "metadata": {},
   "source": [
    "### What Problems are solved by it\n",
    "\n",
    "- **Predictive Modelling** to estimate a new observation --> **regression**\n",
    "- **Explanatory Modelling** to describe the outcome when an input changes --> **classifiers**\n",
    "- **Optimizaion** to find the most relevant inputs for an optimal performance --> **dimmenstionality reduction**\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- **Supervised** Learning if you have labeled data available\n",
    "- **Unsupervised** Learning if no labels are available but you want to find patterns / clusters / structure\n",
    "- **Reinforcement** Learning to learn policies\n",
    "\n",
    "\n",
    "<img src=\"mindmaps/machine_learning_mind_map_6.png\" width=\"100%\"/>\n",
    "\n",
    "note that **decision tree** and **random forrest** classifiers are missing on this image\n",
    "\n",
    "### Performance Measurement Techniques\n",
    "\n",
    "What should be optimized?\n",
    "--> generally speaking: some score on the test set (not the training set)\n",
    "\n",
    "| name | calc |\n",
    "|:-----|:-----|\n",
    "| Accuracy | $$\\frac{correct}{all}=(1-error)$$ |\n",
    "| Error | $$\\frac{wrong}{all}=(1-accuracy)$$ |\n",
    "| Precision | $$\\frac{TP}{TP+FP}$$ |\n",
    "| Recall / Sensitivity | $$\\frac{TP}{TP+FN}$$ |\n",
    "| Specifity | $$\\frac{TN}{TN+FP}$$ |\n",
    "| F1 Score | $$2\\frac{Precision \\cdot Recall}{Precision + Recall}$$ |\n",
    "\n",
    "\n",
    "#### Recall Precision Curve (RPC)\n",
    "\n",
    "\n",
    "\n",
    "#### Recall Operator Curve (ROC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aecee25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Basics\n",
    "\n",
    "### Explain in your own words what _overfitting_ and _underfitting_ is\n",
    "\n",
    "(guaranteed exam question)\n",
    "\n",
    "**Overfitting** is when the model is too detailed and only learns the data by heart instead of generalizing and simplifying the data into a usable model.\n",
    "\n",
    "**Underfitting** is when the model is too simple and not able to fit important variations in the data.\n",
    "\n",
    "### Explain \"_the curse of dimensionality_\" (with an example)\n",
    "\n",
    "The more dimmenstions a dataset has, the more data is required to draw relevant conclusions from this dataset. \n",
    "The amount of data needed to support the result often grows exponentially with the dimensionality.\n",
    "\n",
    "**Example**: Say, you dropped a coin on a 100-meter line. How do you find it? Simple, just walk on the line and search. But what if it’s 100 x 100 sq. m. field? It’s already getting tough, trying to search a (roughly) football ground for a single coin. But what if it’s 100 x 100 x 100 cu.m space?! \n",
    "\n",
    "\n",
    "### What is the \"_no free lunch theorem_\"?\n",
    "\n",
    "For good generalization performance, there is no context-independent or \n",
    "usage-independent reason to favor one learning method over another.\n",
    "\n",
    "### What is \"_Occam's Razor_\"?\n",
    "\n",
    "When presented with competing hypotheses that make the same predictions, one should select the solution with the fewest assumptions.\n",
    "\n",
    "\n",
    "### Explain the \"_Bias Variance Dilemma_\":\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\n",
    "\n",
    "Adding more basis functions in a linear model . . .\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| . . . decreases model bias. | ✅ |  |\n",
    "| . . . decreases estimation bias.  |  | ❌ |\n",
    "| . . . decreases variance.  |  | ❌ |\n",
    "| . . . doesn’t aﬀect bias and variance.  |  | ❌ |\n",
    "\n",
    "\n",
    "### Can a training Error = 0 always be achieved?\n",
    "\n",
    "(general question)\n",
    "\n",
    "(**for which algorithm is this true?**) **No**. The model is learning a function (every input maps to a unique output). \n",
    "So, two different outputs for the very same feature value is not possible!\n",
    "\n",
    "In other words, it depends on the model. If the model is too simple there will be underfitting with a lot of error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc86d7a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Classifiers\n",
    "\n",
    "### What is the difference between a classifier and an estimator?\n",
    "\n",
    "\n",
    "\n",
    "### What is the difference between a generative model and a discriminative model?\n",
    "\n",
    "- A **Generative** Model explicitly models the actual distribution of each class.\n",
    "- A **Discriminative** model models the decision boundary between the classes. \n",
    "\n",
    "**Generative classifiers**\n",
    "\n",
    "- Naïve Bayes\n",
    "- Bayesian networks\n",
    "- Markov random fields\n",
    "- Hidden Markov Models (HMM)\n",
    "\n",
    "**Discriminative Classifiers**\n",
    "\n",
    "- Logistic regression\n",
    "- Suport Vector Machine (SVM)\n",
    "- Traditional neural networks\n",
    "- k-Nearest neighbour (KNN)\n",
    "- Conditional Random Fields (CRF)\n",
    "\n",
    "What happens when training data is biased over one class in Generative Model?\n",
    "What happens when training data is biased over one class in Discriminative Models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bde6d3",
   "metadata": {},
   "source": [
    "## KNN - k-nearest Neighbour\n",
    "\n",
    "> KNN is good for low dimmensions\n",
    "> - for many features (e.g. pixles) the data must be broken down\n",
    "\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| The classiﬁcation accuracy is better with larger values of k. |  | ❌ | \n",
    "| The decision boundary is smoother with smaller values of k.  |  | ❌ |\n",
    "| The decision boundary is linear. |  | ❌ |\n",
    "| k-NN does not require an explicit training step. | ✅ |  |\n",
    "\n",
    "### How can you prevent K-means algorithm from getting stuck in bad local optima ?\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| Set the same seed value for each run. |  | ❌ |\n",
    "| Use multiple random initializations.  | ✅ |  |\n",
    "| Taking bootstrap samples of the data and run it several times. | ✅ |  |\n",
    "| Using K-means++ | ✅ |  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9a0e7",
   "metadata": {},
   "source": [
    "## SVM/SVC - Support Vector Machine/Classifier\n",
    "\n",
    "### What is the fundamental idea behind SVMs?\n",
    "\n",
    "> The fundamental idea behind Support Vector Machines is to ﬁt the widest possible «street»between the classes. In other words, the goal is to have the largest possible margin between the decision boundary that separates the two classes and the training instances.\n",
    "When performing soft margin classiﬁcation, the SVM searches for a compromise between perfectly separating the two classes and having the widest possible street (i.e., a few in-stances may end up on the street). Another key idea is to use kernels when training on nonlinear datasets.\n",
    "\n",
    "### What is a support vector?\n",
    "\n",
    "> After training an SVM, a support vector is any instance located on the «street»(see the previous answer), including its border. The decision boundary is entirely determined by the support vectors. Any instance that is not a support vector (i.e., oﬀ the street) has no inﬂuence whatsoever; you could remove them, add more instances, or move them around, and as long as they stay oﬀ the street they won’t aﬀect the decision boundary. Computing the predictions only involves the support vectors, not the whole training set.\n",
    "\n",
    "### Why is it important to scale the inputs when using SVM?\n",
    "\n",
    "> SVMs try to ﬁt the largest possible «street»between the classes (see the ﬁrst answer), so if the training set is not scaled, the SVM will tend to neglect small features.\n",
    "\n",
    "### Can an SVM output a conﬁdence score when it classiﬁes an instance? What about a probability?\n",
    "\n",
    "> An SVM classiﬁer can output the distance between the test instance and the decision boundary, and you can use this as a conﬁdence score. However, this score cannot be directly converted into an estimation of the class probability. If you set probability=True when creating an SVM in Scikit-Learn, then after training it will calibrate the probabilities using Logistic Regression on the SVM’s scores (trained by an additional ﬁve-fold cross-validation on the training data). This will add the predict_proba() and predict_log_proba() methods to the SVM.\n",
    "\n",
    "### Should you use the primal or the dual form of the SVM problem to train a  model on a training set with millions of instances and hundreds of features?\n",
    "\n",
    "> This question applies only to linear SVMs since kernelized can only use the dual form. The computational complexity of the primal form of the SVM problem is proportional to the number of training instances N, while the computational complexity of the dual form is proportional to a number between N2 and N3. So if there are millions of instances, you should deﬁnitely use the primal form, because the dual form will be much too slow.\n",
    "\n",
    "### Say you trained an SVM classiﬁer with an RBF kernel. It seems to underﬁt  the training set: should you increase or decrease γ? What about C?\n",
    "\n",
    "> If an SVM classiﬁer trained with an RBF kernel underﬁts the training set, there might be too much regularization. To decrease it, you need to increase γ or C (or both).\n",
    "\n",
    "### What are the advantages of SVM?\n",
    "\n",
    "> \"SVM are still eﬀective in cases where number of dimensions d is greater than the number of samples N\"\n",
    "\n",
    "### What are disadvantages of SVM?\n",
    "\n",
    "- Noisy measurements because only a few points define the border\n",
    "\n",
    "### What are Lagrange-Multipliers and why are they used in SVM?\n",
    "\n",
    "- To get rid of the linear inequality constraints,\n",
    "\n",
    "### What is a dual form of an optimizaiton problem?\n",
    "\n",
    "\n",
    "### What is the difference between the dual-version and the primal-version of a SVM classifier?\n",
    "\n",
    "\n",
    "### What does the geometric margin say?\n",
    "\n",
    "\n",
    "### How do you distinguish \"linearly non-separable classes\"?\n",
    "\n",
    "\n",
    "### What does the Kernel Trick do?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6f863",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "> However, although naive Bayes is known as a decent classiﬁer,\n",
    "it is known to be a bad estimator, so the probability outputs from `predict_proba` are not to be\n",
    "taken too seriously.\n",
    "\n",
    "### What is a weakness of Bayes Classifier and what can be done against it?\n",
    "\n",
    "- The classifer becomes weak, if a certain state was never observed\n",
    "- Use Laplace Smoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870d246",
   "metadata": {},
   "source": [
    "## Decision Tree (classifier)\n",
    "\n",
    "### How can you improove ... ?\n",
    "\n",
    "\n",
    "\n",
    "### What is \"_boosting_\" ?\n",
    "\n",
    "\n",
    "### What is \"_bagging_\" ?\n",
    "\n",
    "\n",
    "### What is an out of bag error?\n",
    "\n",
    "\n",
    "\n",
    "## Random Forrest Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef190d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Clustering (classification of unlabelled data)\n",
    "\n",
    "### What is the difference between Hard- and Soft Clustering?\n",
    "\n",
    "**Hard Clustering** \n",
    "\n",
    "**Soft Clustering**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e57bc8",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "###  What are the basic assumptions of the k-Means algorithm? How does it work? \n",
    "\n",
    "- Each data point is closer to its own cluster center than the other cluster centers\n",
    "- A cluster center is the arithmetic mean of all the points that belong to the cluster.\n",
    "\n",
    "### What are Advantages and Disadvantages of the k-means Clustering?\n",
    "\n",
    "Advantages:\n",
    "- \n",
    "\n",
    "Disadvantages:\n",
    "- K-Means is known as a hard clustering algorithm because clusters are not allowed to overlap\n",
    "- k-means cannot learn the optimal number of clusters from the data. If we ask for six clusters it will find six clusters, which may or may not be meaningful.\n",
    "    + use a more complex clustering algorithm like Gaussian Mixture Models, or one that can choose a suitable number of clusters (DBSCAN, mean-shift, affinity propagation)\n",
    "- k-means is terrible for non-linear data: this results because of the assumption that points will be closer to their own cluster center than others\n",
    "    + transform data into higher dimension where linear separation is possible e.g., spectral clustering\n",
    "- A resulting issue of K-Means' circular boundaries is that it has no way to account for oblong or elliptical clusters.\n",
    "    + 1. measure uncertainty in cluster assignments by comparing distances to all cluster centers\n",
    "    + 2. allow for flexibility in the shape of the cluster boundaries by using ellipses\n",
    "- \n",
    "\n",
    "### What is the k-means++ Algorithm?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9055fc3f",
   "metadata": {},
   "source": [
    "## EM - Expectation Maximization\n",
    "\n",
    "### Explain how the expecation maximization algorithm (EM) works.\n",
    "\n",
    "\n",
    "\n",
    "### List a ﬁve data science applications where EM can be used.\n",
    "\n",
    "\n",
    "\n",
    "### How would you prove that the EM algorithm converges to the maximum likelihood estimate of the hypothesis made?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc89ae",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Dimmensionality Reduction\n",
    "\n",
    "### Which dimmensionality reduction algorithm do you know?\n",
    "\n",
    "- **Kernel PCA** is generally well suited in reducing the dimensionality of high dimensional, nonlinear datasets. By applying the kernel trick, a nonlinear mapping is applied to the input data, actually increasing the dimensionality even more. The kernel however can be evaluated in dataspace. The problem complexity is given by the number of data points.\n",
    "- **Local Linear Embedding (LLE)** reduces dimensionality while trying to preserve the distances between close instances only.\n",
    "- **Isomap** creates a graph by connecting each instance to its nearest neighbors, then reduces dimensionality while trying to preserve the geodesic distances between the instances.\n",
    "- **t-Distributed Stochastic Neighbor Embedding (t-SNE)** reduces dimensionality while trying to keep similar instances close and dissimilar instances apart. It is mostly used for visualization, in particular to visualize clusters of instances in high-dimensional space (e.g., to visualize the MNIST images in 2D).\n",
    "- **Linear Discriminant Analysis (LDA)** is actually a classiﬁcation algorithm. During training it learns the most discriminative axes between the classes. These axes can be used to deﬁne a hyperplane onto which to project the data. The projection will keep classes as far apart as possible, so LDA is a good technique to reduce dimensionality before running another classiﬁcation algorithm such as an SVM classiﬁer.\n",
    "\n",
    "### How can you evaluate the performance of a dimensionality reduction algorithm?\n",
    "\n",
    "(general question)\n",
    "\n",
    "One way to measure the performance of the reduction alone is to apply the reverse transformation and measure the reconstruction error. This only works, if an inverse can be aplied.\n",
    "\n",
    "It depends on what performance measurement the entire machine learning task optimizes for. In order for this question to be answered, a performence metric must also be defined (e.g. Precision, Recall, f1-score etc.)\n",
    "\n",
    "\n",
    "### Does it make sense to chain two different dimensionality reduction algorithms?\n",
    "\n",
    "(general question)\n",
    "\n",
    "It depends on the task. It could help to increase the speed.\n",
    "\n",
    "> A common example is using PCA to quickly get rid of a large number of useless dimensions, then applying another much slower dimensionality reduction algorithm, such as LLE. This two-step approach will likely yield the same performance as using LLE only, but in a fraction of the time.\n",
    "\n",
    "### What are the main motivations for reducing a dataset’s dimensionality?\n",
    "\n",
    "- noise reduction, removal\n",
    "- removal of noise and redundant features for classiﬁcation tasks\n",
    "- algorithms perform better and faster with less dimensions\n",
    "- removes redundant features\n",
    "- allows to filter for features that matter and discard features that have no additional information\n",
    "- visualization of high dimensional data\n",
    "- data compression\n",
    "\n",
    "### What are the main drawbacks of dimensionality reduction techniques?\n",
    "\n",
    "- information is lost on purpose\n",
    "- linear methods are not able to unwrap / detect substructures\n",
    "- the reduction process is again a step in the machine learning chain that uses processing power and time\n",
    "- adds complexity to the leaerning pipeline\n",
    "- transformed spaces are hard to interpret by humans\n",
    "\n",
    "### Once a dataset’s dimensionality has been reduced, is it possible to reverse the operation? If so, how? If not, why?\n",
    "\n",
    "(general question)\n",
    "\n",
    "For some methods **yes**. The data can be decompressed but will be contaminated with some artifacts because some information was lost.\n",
    "\n",
    "Also, not all methods have an inverse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c59b0",
   "metadata": {},
   "source": [
    "## PCA - Principle Component Analysis\n",
    "\n",
    "\n",
    "### Can PCA be used to reduce the dimensionality of a highly nonlinear dataset? Which methods can alternatively be used?\n",
    "\n",
    "No, PCA/NDS acts globally.\n",
    "\n",
    "Use a Kernel instead. \n",
    "\n",
    "> If highly nonlinear distribution, which would you select ( ... ) ?\n",
    "\n",
    "###  Suppose you perform a PCA on a 1000-dimensional dataset, setting the explained variance to 95%. How many dimensions will the resulting dataset have?\n",
    "\n",
    "(general question)\n",
    "\n",
    "cannot be answered. depends on data\n",
    "\n",
    "### In which cases would you use incremental PCA, randomized PCA or kernel PCA?\n",
    "\n",
    "\n",
    "- **Randomized PCA** is useful when you want to considerably reduce dimensionality and the dataset ﬁts in memory; in this case, it is much faster than regular PCA. Finally, Kernel PCA is useful for nonlinear datasets.\n",
    "- **Randomized PCA** to save computation time by selecting a randomized subset of the data. \n",
    "- **kernel PCA** is used for nonlinear datasets\n",
    "- **Regular PCA** is the default, but it works only if the dataset ﬁts in memory.\n",
    "- **Incremental PCA** is useful for large datasets that don’t ﬁt in memory, but it is slower than regular PCA, so if the dataset ﬁts in memory you should prefer regular PCA. Incremental PCA is also useful for online tasks, when you need to apply PCA on the ﬂy, every time a new instance arrives.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ae5f1",
   "metadata": {},
   "source": [
    "## Kernel Functions\n",
    "\n",
    "\n",
    "### Explain what a kernel is.\n",
    "\n",
    "\n",
    "\n",
    "### List four commonly used kernels $k(x, x′)$ in Machine Learning.\n",
    "\n",
    "\n",
    "\n",
    "### Show, that the RBS-kernel is symmetric and positive semi-deﬁnite.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a29c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Training & Validation\n",
    "\n",
    "\n",
    "### Debugging Questions\n",
    "\n",
    "Suppose you are using some classiﬁer algorithm on a given training set. The training error\n",
    "is acceptable. However, it makes unacceptably large errors in its predictions on unseen data.\n",
    "What should be tried next?\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| Get more training samples. | ✅ |  |\n",
    "| Try larger sets of features, e.g. by generating polynomial features. |  | ❌ |\n",
    "| Decrease the regularization parameter λ if regularization is used.  |  | ❌ |\n",
    "| Create a meta learner, e.g. a voting or bagging classiﬁer out of several diﬀerent classiﬁers or build an ensemble of classiﬁers. | ✅ |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adabcba",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "1. Split Data into Training and Test data\n",
    "2. Training Data + Cross-Validation -> best Hyperparameters\n",
    "3. Retrain model with best Hyperparameters on the entire Training Data\n",
    "4. Test Data + Model -> estimate of generalization error\n",
    "\n",
    "Note: The estimate of the generalization error can be cross-validated as well\n",
    "\n",
    "Advantages:\n",
    "- make to most out of the examples!\n",
    "- averages out do individual performance of the splits (especially for few data-points)\n",
    "\n",
    "- 2-fold cross-validation \n",
    "- k-fold cross-validation \n",
    "- LOOCV (leave-one-out-...)\n",
    "\n",
    "\n",
    "## Validation Curve\n",
    "\n",
    "\n",
    "\n",
    "## Hyper Parameter Tuning\n",
    "\n",
    "### How do you tune hyper parameters?\n",
    "\n",
    "- use grid search (linear or logarithmic step sizes)\n",
    "\n",
    "### What are disadvantages of grid search?\n",
    "\n",
    "- Smaller step size corresponds to more scenarios to be tested which increases the training time\n",
    "- additional hyperparameters increase the effort exponentially\n",
    "- with large step sizes there is the risk to end up in a local maxima/minima and miss the global optimum\n",
    "\n",
    "### What does grid search optimize?\n",
    "(general question)\n",
    "\n",
    "It depends on what the overall algorithm wants to achieve. So a metric must be selected (e.g. Accuracy Score, Precision, f1-Score etc.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde76f6",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Regression\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "|  LASSO regularization uses the L2 norm of the vector of parameters to be estimated. |  | ❌ |\n",
    "|  LASSO regularization can be used for feature selection, because it forces a spase output where some parameters are set to zero.  | ✅ |  |\n",
    "| Regularization for for any learner can be done by adding a penalty to the cost (loss) function that penalizes too complex models. | ✅ |  |\n",
    "| The parameter etimates for ridge regression can be calculated directy using an analytical solution. | ✅ |  |\n",
    "\n",
    "### Which of the following statements about regularization and the regularization parameter λ are correct ?\n",
    "\n",
    "| are these statements `true` or `false` ? | `true` | `false` |\n",
    "|:------|:--:|:--:|\n",
    "| Using too large a value of λ can cause your hypothesis to underﬁt the data. | ✅ |  |\n",
    "|  Using too large a value of λ can cause your hypothesis to overﬁt the data.  |  | ❌ |\n",
    "| Using a very large value of λ cannot hurt the performance of your hypothesis. |  | ❌ |\n",
    "| None of the above.  |  | ❌ |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Explain \"regression to mean\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32980d",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb7771",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Reinforcement Learning \n",
    "\n",
    "\n",
    "### What is the definition of a _finite Markov decision process_ (MDP)?\n",
    "\n",
    "\n",
    "### What is the definition of a _Markov reward process_ (MRP)?\n",
    "\n",
    "\n",
    "### What is Q-learning?\n",
    "\n",
    "\n",
    "### What is Value Iteration?\n",
    "\n",
    "\n",
    "### the diﬀerence between on-policy and oﬀ-policy learning.\n",
    "\n",
    "\n",
    "### explain the diﬀerence between value iteration and policy iteration.\n",
    "\n",
    "\n",
    "### the trade-oﬀ between exploitation and exploration.\n",
    "\n",
    "\n",
    "### Is the MDP framework adequate to usefully represent all goal-directed learning tasks? Can you think of any clear exceptions?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e15645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
